{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Installing specific version of plotly to avoid Invalid property for color error in recent version which needs change in layout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.plotly as py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-01 00:00:00</td>\n",
       "      <td>10844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-01 00:30:00</td>\n",
       "      <td>8127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-01 01:00:00</td>\n",
       "      <td>6210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-01 01:30:00</td>\n",
       "      <td>4656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-01 02:00:00</td>\n",
       "      <td>3820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  value\n",
       "0  2014-07-01 00:00:00  10844\n",
       "1  2014-07-01 00:30:00   8127\n",
       "2  2014-07-01 01:00:00   6210\n",
       "3  2014-07-01 01:30:00   4656\n",
       "4  2014-07-01 02:00:00   3820"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_df=pd.read_csv(\"C:\\\\Users\\\\M1085732\\\\Music\\\\CBM\\\\Vibrartion_Analysis\\\\Time-Series-Analysis\\\\nyc_taxi.csv\")\n",
    "time_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df['timestamp'] = pd.to_datetime(time_series_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_df = time_series_df.set_index('timestamp').resample('H').mean().reset_index()\n",
    "time_series_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stationary vs. Non-Stationary\n",
    "\n",
    "In a stationary time series, statistical properties such as mean and variance are constant over time. In a non-stationary series, these properties are dependent on time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stationary'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_stationarity(ts_data, column='', signif=0.05, series=False):\n",
    "    if series:\n",
    "        adf_test = adfuller(ts_data, autolag='AIC')\n",
    "    else:\n",
    "        adf_test = adfuller(ts_data[column], autolag='AIC')\n",
    "    p_value = adf_test[1]\n",
    "    if p_value <= signif:\n",
    "        test_result = \"Stationary\"\n",
    "    else:\n",
    "        test_result = \"Non-Stationary\"\n",
    "    return test_result\n",
    "test_stationarity(time_series_df, 'value') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "train = time_series_df[(time_series_df['timestamp'] >= '2014-07-01') & (time_series_df['timestamp'] <= '2015-01-27')]\n",
    "test = time_series_df[(time_series_df['timestamp'] > '2015-01-27')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'value']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\M1085732\\Music\\CBM\\Vibrartion_Analysis\\Time-Series-Analysis\\Arima_Anomaly detection.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/M1085732/Music/CBM/Vibrartion_Analysis/Time-Series-Analysis/Arima_Anomaly%20detection.ipynb#ch0000005?line=3'>4</a>\u001b[0m predict_log\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/M1085732/Music/CBM/Vibrartion_Analysis/Time-Series-Analysis/Arima_Anomaly%20detection.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(test)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/M1085732/Music/CBM/Vibrartion_Analysis/Time-Series-Analysis/Arima_Anomaly%20detection.ipynb#ch0000005?line=5'>6</a>\u001b[0m     model \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mtsa\u001b[39m.\u001b[39;49mSARIMAX(history)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/M1085732/Music/CBM/Vibrartion_Analysis/Time-Series-Analysis/Arima_Anomaly%20detection.ipynb#ch0000005?line=6'>7</a>\u001b[0m     model_fit \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(disp\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/M1085732/Music/CBM/Vibrartion_Analysis/Time-Series-Analysis/Arima_Anomaly%20detection.ipynb#ch0000005?line=7'>8</a>\u001b[0m     output \u001b[39m=\u001b[39m model_fit\u001b[39m.\u001b[39mforecast()\n",
      "File \u001b[1;32mc:\\Users\\M1085732\\Music\\CBM\\Vibrartion_Analysis\\Vib.env\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:328\u001b[0m, in \u001b[0;36mSARIMAX.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, trend, measurement_error, time_varying_regression, mle_regression, simple_differencing, enforce_stationarity, enforce_invertibility, hamilton_representation, concentrate_scale, trend_offset, use_exact_diffuse, dates, freq, missing, validate_specification, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m    319\u001b[0m              seasonal_order\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m), trend\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    320\u001b[0m              measurement_error\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, time_varying_regression\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m              freq\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, missing\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, validate_specification\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    326\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec \u001b[39m=\u001b[39m SARIMAXSpecification(\n\u001b[0;32m    329\u001b[0m         endog, exog\u001b[39m=\u001b[39;49mexog, order\u001b[39m=\u001b[39;49morder, seasonal_order\u001b[39m=\u001b[39;49mseasonal_order,\n\u001b[0;32m    330\u001b[0m         trend\u001b[39m=\u001b[39;49mtrend, enforce_stationarity\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, enforce_invertibility\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    331\u001b[0m         concentrate_scale\u001b[39m=\u001b[39;49mconcentrate_scale, dates\u001b[39m=\u001b[39;49mdates, freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m    332\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing, validate_specification\u001b[39m=\u001b[39;49mvalidate_specification)\n\u001b[0;32m    333\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params \u001b[39m=\u001b[39m SARIMAXParams(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spec)\n\u001b[0;32m    335\u001b[0m     \u001b[39m# Save given orders\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\M1085732\\Music\\CBM\\Vibrartion_Analysis\\Vib.env\\lib\\site-packages\\statsmodels\\tsa\\arima\\specification.py:458\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m (validate_specification \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m faux_endog \u001b[39mand\u001b[39;00m\n\u001b[0;32m    453\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSARIMAX models require univariate `endog`. Got\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    455\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m shape \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    457\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_missing \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 458\u001b[0m     \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m faux_endog \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39;49misnan(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendog)))\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "history = [x for x in train]\n",
    "print(history)\n",
    "predictions = list()\n",
    "predict_log=list()\n",
    "for t in range(len(test)):\n",
    "    model = sm.tsa.SARIMAX(history)\n",
    "    model_fit = model.fit(disp=0)\n",
    "    output = model_fit.forecast()\n",
    "    predict_log.append(output[0])\n",
    "    yhat = 10**output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test[t]\n",
    "    history.append(obs)\n",
    "   # print('predicted=%f, expected=%f' % (output[0], obs))\n",
    "#error = math.sqrt(mean_squared_error(test_log, predict_log))\n",
    "#print('Test rmse: %.3f' % error)\n",
    "# plot\n",
    "figsize=(12, 7)\n",
    "plt.figure(figsize=figsize)\n",
    "pyplot.plot(test,label='Actuals')\n",
    "pyplot.plot(predictions, color='red',label='Predicted')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyramid-arima\n",
    "from pyramid.arima import auto_arima\n",
    "stepwise_model = auto_arima(train, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=7,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train, test = actual_vals[0:-70], actual_vals[-70:]\n",
    "train_log, test_log = np.log10(train), np.log10(test)\n",
    "# split data into train and test-sets\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "predict_log=list()\n",
    "for t in range(len(test_log)):\n",
    "    #model = sm.tsa.SARIMAX(history, order=my_order, seasonal_order=my_seasonal_order,enforce_stationarity=False,enforce_invertibility=False)\n",
    "    stepwise_model.fit(history)\n",
    "    output = stepwise_model.predict(n_periods=1)\n",
    "    predict_log.append(output[0])\n",
    "    yhat = 10**output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test_log[t]\n",
    "    history.append(obs)\n",
    "    #print('predicted=%f, expected=%f' % (output[0], obs))\n",
    "#error = math.sqrt(mean_squared_error(test_log, predict_log))\n",
    "#print('Test rmse: %.3f' % error)\n",
    "# plot\n",
    "figsize=(12, 7)\n",
    "plt.figure(figsize=figsize)\n",
    "pyplot.plot(test,label='Actuals')\n",
    "pyplot.plot(predictions, color='red',label='Predicted')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_df=pd.DataFrame()\n",
    "predicted_df['load_date']=time_series_df['load_date'][-70:]\n",
    "predicted_df['actuals']=test\n",
    "predicted_df['predicted']=predictions\n",
    "predicted_df.reset_index(inplace=True)\n",
    "del predicted_df['index']\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def detect_classify_anomalies(df,window):\n",
    "    df.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "    df.fillna(0,inplace=True)\n",
    "    df['error']=df['actuals']-df['predicted']\n",
    "    df['percentage_change'] = ((df['actuals'] - df['predicted']) / df['actuals']) * 100\n",
    "    df['meanval'] = df['error'].rolling(window=window).mean()\n",
    "    df['deviation'] = df['error'].rolling(window=window).std()\n",
    "    df['-3s'] = df['meanval'] - (2 * df['deviation'])\n",
    "    df['3s'] = df['meanval'] + (2 * df['deviation'])\n",
    "    df['-2s'] = df['meanval'] - (1.75 * df['deviation'])\n",
    "    df['2s'] = df['meanval'] + (1.75 * df['deviation'])\n",
    "    df['-1s'] = df['meanval'] - (1.5 * df['deviation'])\n",
    "    df['1s'] = df['meanval'] + (1.5 * df['deviation'])\n",
    "    cut_list = df[['error', '-3s', '-2s', '-1s', 'meanval', '1s', '2s', '3s']]\n",
    "    cut_values = cut_list.values\n",
    "    cut_sort = np.sort(cut_values)\n",
    "    df['impact'] = [(lambda x: np.where(cut_sort == df['error'][x])[1][0])(x) for x in\n",
    "                               range(len(df['error']))]\n",
    "    severity = {0: 3, 1: 2, 2: 1, 3: 0, 4: 0, 5: 1, 6: 2, 7: 3}\n",
    "    region = {0: \"NEGATIVE\", 1: \"NEGATIVE\", 2: \"NEGATIVE\", 3: \"NEGATIVE\", 4: \"POSITIVE\", 5: \"POSITIVE\", 6: \"POSITIVE\",\n",
    "              7: \"POSITIVE\"}\n",
    "    df['color'] =  df['impact'].map(severity)\n",
    "    df['region'] = df['impact'].map(region)\n",
    "    df['anomaly_points'] = np.where(df['color'] == 3, df['error'], np.nan)\n",
    "    df = df.sort_values(by='load_date', ascending=False)\n",
    "    df.load_date = pd.to_datetime(df['load_date'].astype(str), format=\"%Y-%m-%d\")\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomaly(df,metric_name):\n",
    "    #error = pd.DataFrame(Order_results.error.values)\n",
    "    #df = df.sort_values(by='load_date', ascending=False)\n",
    "    #df.load_date = pd.to_datetime(df['load_date'].astype(str), format=\"%Y%m%d\")\n",
    "    dates = df.load_date\n",
    "    #meanval = error.rolling(window=window).mean()\n",
    "    #deviation = error.rolling(window=window).std()\n",
    "    #res = error\n",
    "#upper_bond=meanval + (2 * deviation)\n",
    "    #lower_bond=meanval - (2 * deviation)\n",
    "#anomalies = pd.DataFrame(index=res.index, columns=res.columns)\n",
    "    #anomalies[res < lower_bond] = res[res < lower_bond]\n",
    "    #anomalies[res > upper_bond] = res[res > upper_bond]\n",
    "    bool_array = (abs(df['anomaly_points']) > 0)\n",
    "#And a subplot of the Actual Values.\n",
    "    actuals = df[\"actuals\"][-len(bool_array):]\n",
    "    anomaly_points = bool_array * actuals\n",
    "    anomaly_points[anomaly_points == 0] = np.nan\n",
    "#Order_results['meanval']=meanval\n",
    "    #Order_results['deviation']=deviation\n",
    "color_map= {0: \"'rgba(228, 222, 249, 0.65)'\", 1: \"yellow\", 2: \"orange\", 3: \"red\"}\n",
    "    table = go.Table(\n",
    "    domain=dict(x=[0, 1],\n",
    "                y=[0, 0.3]),\n",
    "    columnwidth=[1, 2 ],\n",
    "    #columnorder=[0, 1, 2,],\n",
    "    header = dict(height = 20,\n",
    "                  values = [['<b>Date</b>'],['<b>Actual Values </b>'],\n",
    "                            ['<b>Predicted</b>'], ['<b>% Difference</b>'],['<b>Severity (0-3)</b>']],\n",
    "                 font = dict(color=['rgb(45, 45, 45)'] * 5, size=14),\n",
    "                  fill = dict(color='#d562be')),\n",
    "    cells = dict(values = [df.round(3)[k].tolist() for k in ['load_date', 'actuals', 'predicted',\n",
    "                                                               'percentage_change','color']],\n",
    "                 line = dict(color='#506784'),\n",
    "                 align = ['center'] * 5,\n",
    "                 font = dict(color=['rgb(40, 40, 40)'] * 5, size=12),\n",
    "                 #format = [None] + [\",.4f\"] + [',.4f'],\n",
    "#suffix=[None] * 4,\n",
    "                 suffix=[None] + [''] + [''] + ['%'] + [''],\n",
    "                 height = 27,\n",
    "                 #fill = dict(color=['rgb(235, 193, 238)', 'rgba(228, 222, 249, 0.65)']))\n",
    "                 fill=dict(color=  # ['rgb(245,245,245)',#unique color for the first column\n",
    "                      [df['color'].map(color_map)],\n",
    "                      )\n",
    "    ))\n",
    "#df['ano'] = np.where(df['color']==3, df['error'], np.nan)\n",
    "anomalies = go.Scatter(name=\"Anomaly\",\n",
    "                       x=dates,\n",
    "                       xaxis='x1',\n",
    "                       yaxis='y1',\n",
    "                       y=df['anomaly_points'],\n",
    "                       mode='markers',\n",
    "                       marker = dict(color ='red',\n",
    "                      size = 11,line = dict(\n",
    "                                         color = \"red\",\n",
    "                                         width = 2)))\n",
    "upper_bound = go.Scatter(hoverinfo=\"skip\",\n",
    "                         x=dates,\n",
    "                         showlegend =False,\n",
    "                         xaxis='x1',\n",
    "                         yaxis='y1',\n",
    "                         y=df['3s'],\n",
    "                         marker=dict(color=\"#444\"),\n",
    "                         line=dict(\n",
    "                             color=('rgb(23, 96, 167)'),\n",
    "                             width=2,\n",
    "                             dash='dash'),\n",
    "                         fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "                         fill='tonexty')\n",
    "lower_bound = go.Scatter(name='Confidence Interval',\n",
    "                          x=dates,\n",
    "                         xaxis='x1',\n",
    "                         yaxis='y1',\n",
    "                          y=df['-3s'],\n",
    "                          marker=dict(color=\"#444\"),\n",
    "                          line=dict(\n",
    "                              color=('rgb(23, 96, 167)'),\n",
    "                              width=2,\n",
    "                              dash='dash'),\n",
    "                          fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "                          fill='tonexty')\n",
    "Actuals = go.Scatter(name= 'Actuals',\n",
    "                     x= dates,\n",
    "                     y= df['actuals'],\n",
    "                    xaxis='x2', yaxis='y2',\n",
    "                     mode='line',\n",
    "                     marker=dict(size=12,\n",
    "                                 line=dict(width=1),\n",
    "                                 color=\"blue\"))\n",
    "Predicted = go.Scatter(name= 'Predicted',\n",
    "                     x= dates,\n",
    "                     y= df['predicted'],\n",
    "                    xaxis='x2', yaxis='y2',\n",
    "                     mode='line',\n",
    "                     marker=dict(size=12,\n",
    "                                 line=dict(width=1),\n",
    "                                 color=\"orange\"))\n",
    "# create plot for error...\n",
    "    Error = go.Scatter(name=\"Error\",\n",
    "                   x=dates, y=df['error'],\n",
    "                   xaxis='x1',\n",
    "                   yaxis='y1',\n",
    "                   mode='line',\n",
    "                   marker=dict(size=12,\n",
    "                               line=dict(width=1),\n",
    "                               color=\"red\"),\n",
    "                   text=\"Error\")\n",
    "anomalies_map = go.Scatter(name = \"anomaly actual\",\n",
    "                                   showlegend=False,\n",
    "                                   x=dates,\n",
    "                                   y=anomaly_points,\n",
    "                                   mode='markers',\n",
    "                                   xaxis='x2',\n",
    "                                   yaxis='y2',\n",
    "                                    marker = dict(color =\"red\",\n",
    "                                  size = 11,\n",
    "                                 line = dict(\n",
    "                                     color = \"red\",\n",
    "                                     width = 2)))\n",
    "Mvingavrg = go.Scatter(name=\"Moving Average\",\n",
    "                           x=dates,\n",
    "                           y=df['meanval'],\n",
    "                           mode='line',\n",
    "                           xaxis='x1',\n",
    "                           yaxis='y1',\n",
    "                           marker=dict(size=12,\n",
    "                                       line=dict(width=1),\n",
    "                                       color=\"green\"),\n",
    "                           text=\"Moving average\")\n",
    "axis=dict(\n",
    "    showline=True,\n",
    "    zeroline=False,\n",
    "    showgrid=True,\n",
    "    mirror=True,\n",
    "    ticklen=4,\n",
    "    gridcolor='#ffffff',\n",
    "    tickfont=dict(size=10))\n",
    "layout = dict(\n",
    "    width=1000,\n",
    "    height=865,\n",
    "    autosize=False,\n",
    "    title= metric_name,\n",
    "    margin = dict(t=75),\n",
    "    showlegend=True,\n",
    "    xaxis1=dict(axis, **dict(domain=[0, 1], anchor='y1', showticklabels=True)),\n",
    "    xaxis2=dict(axis, **dict(domain=[0, 1], anchor='y2', showticklabels=True)),\n",
    "    yaxis1=dict(axis, **dict(domain=[2 * 0.21 + 0.20 + 0.09, 1], anchor='x1', hoverformat='.2f')),\n",
    "    yaxis2=dict(axis, **dict(domain=[0.21 + 0.12, 2 * 0.31 + 0.02], anchor='x2', hoverformat='.2f')))\n",
    "fig = go.Figure(data = [table,anomalies,anomalies_map,\n",
    "                        upper_bound,lower_bound,Actuals,Predicted,\n",
    "                        Mvingavrg,Error], layout = layout)\n",
    "iplot(fig)\n",
    "pyplot.show()\n",
    "classify_df=detect_classify_anomalies(predicted_df,7)\n",
    "classify_df.reset_index(inplace=True)\n",
    "del classify_df['index']\n",
    "plot_anomaly(classify_df,\"metric_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('Vib.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "441ddbc04b489d2063928333e0c797ff7d144f21a88cfddd13e19b4c1bc4e060"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
